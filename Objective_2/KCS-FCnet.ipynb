{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set-up","metadata":{}},{"cell_type":"markdown","source":"## Installing libraries and libcudnn8","metadata":{}},{"cell_type":"code","source":"## only with GPU\nimport sys\nsys.path.insert(0,'/kaggle/input/mi-eeg-classmeth/')\n#FILEID = \"1-bPsREsUCOiJHzIqi8DQrfSjTAf5VAW_\"\n!apt-get install --allow-change-held-packages libcudnn8=8.1.1.33-1+cuda11.2 -y\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n!pip install mne\n!pip install scikeras[tensorflow]\n#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n#!unzip MI_EEG_ClassMeth.zip #Package with useful functions for motor imagery classification based in EEG.\n#!dir","metadata":{"execution":{"iopub.status.busy":"2023-07-08T01:58:26.793859Z","iopub.execute_input":"2023-07-08T01:58:26.794683Z","iopub.status.idle":"2023-07-08T02:01:30.417407Z","shell.execute_reply.started":"2023-07-08T01:58:26.794555Z","shell.execute_reply":"2023-07-08T02:01:30.416038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import libraries","metadata":{"papermill":{"duration":0.005353,"end_time":"2022-10-22T21:59:26.046417","exception":false,"start_time":"2022-10-22T21:59:26.041064","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install tensorflow-probability==0.18.* --quiet\n!pip install tensorflow==2.10.* --quiet","metadata":{"execution":{"iopub.status.busy":"2023-05-21T20:32:39.854806Z","iopub.execute_input":"2023-05-21T20:32:39.855789Z","iopub.status.idle":"2023-05-21T20:33:29.841182Z","shell.execute_reply.started":"2023-05-21T20:32:39.855742Z","shell.execute_reply":"2023-05-21T20:33:29.839988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gcpds datasets\nfrom gcpds.databases import GIGA_MI_ME\nfrom gcpds.databases.BCI_Competition_IV import Dataset_2a\nimport gcpds.databases as loaddb\n\n# freq filter \nfrom MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\n\n# general\nimport numpy as np\nfrom scipy.signal import resample\nimport pickle\nimport warnings\nimport mne\nfrom time import time\nwarnings.filterwarnings('ignore')\n\n# tensorlfow \nimport tensorflow as tf\nimport tensorflow_probability as tfp\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, AveragePooling2D, BatchNormalization, Input, Flatten\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.keras.regularizers import L1L2\n\n# scikeras\nfrom scikeras.wrappers import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV,StratifiedShuffleSplit\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score","metadata":{"papermill":{"duration":10.438951,"end_time":"2022-10-22T22:02:26.565555","exception":false,"start_time":"2022-10-22T22:02:16.126604","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-21T20:33:29.845135Z","iopub.execute_input":"2023-05-21T20:33:29.845469Z","iopub.status.idle":"2023-05-21T20:33:37.545793Z","shell.execute_reply.started":"2023-05-21T20:33:29.845438Z","shell.execute_reply":"2023-05-21T20:33:37.54473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define functions","metadata":{}},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-05-21T01:31:46.938814Z","iopub.execute_input":"2023-05-21T01:31:46.94011Z","iopub.status.idle":"2023-05-21T01:31:46.951959Z","shell.execute_reply.started":"2023-05-21T01:31:46.940065Z","shell.execute_reply":"2023-05-21T01:31:46.95037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kappa(y_true, y_pred):\n    return cohen_kappa_score(np.argmax(y_true, axis = 1),np.argmax(y_pred, axis = 1))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T01:32:16.543777Z","iopub.execute_input":"2023-05-21T01:32:16.544375Z","iopub.status.idle":"2023-05-21T01:32:16.556329Z","shell.execute_reply.started":"2023-05-21T01:32:16.544251Z","shell.execute_reply":"2023-05-21T01:32:16.555312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GIGA Science dataset","metadata":{}},{"cell_type":"code","source":"def load_GIGA(db: GIGA_MI_ME,\n              sbj: int,\n              fs: float, \n              f_bank: np.ndarray, \n              vwt: np.ndarray, \n              new_fs: float) -> np.ndarray:\n\n    eeg_ch_names = ['Fp1','Fpz','Fp2',\n              'AF7','AF3','AFz','AF4','AF8',\n              'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n              'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n              'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n              'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n              'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n              'PO7','PO3','POz','PO4','PO8',\n              'O1','Oz','O2',\n              'Iz']\n\n    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n    db.load_subject(sbj)\n    X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    X = X[:,index_eeg_chs,:] #spatial rearrangement\n    X = np.squeeze(tf_repr.transform(X))\n    #Resampling\n    if new_fs == fs:\n        print('No resampling, since new sampling rate same.')\n    else:\n        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n    return X, y","metadata":{"papermill":{"duration":2.730715,"end_time":"2022-10-22T22:02:29.329591","exception":false,"start_time":"2022-10-22T22:02:26.598876","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-21T01:32:17.884123Z","iopub.execute_input":"2023-05-21T01:32:17.884674Z","iopub.status.idle":"2023-05-21T01:32:17.90899Z","shell.execute_reply.started":"2023-05-21T01:32:17.884628Z","shell.execute_reply":"2023-05-21T01:32:17.906316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BCI2a dataset","metadata":{}},{"cell_type":"code","source":"def load_BCICIV2a(db: Dataset_2a,\n               sbj: int,\n               fs: float, \n               f_bank: np.ndarray, \n               vwt: np.ndarray, \n               new_fs: float,\n               num_class: int) -> np.ndarray:\n\n    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n    # training \n    db.load_subject(sbj, mode = 'training')\n    if num_class==4:\n        classes = ['left hand', 'right hand', 'feet', 'tongue']\n    elif num_class==2:\n        classes = ['left hand', 'right hand']\n    X_tr, y_tr = db.get_data(classes=classes) #Load all classes, all channels {EEG, EOG}, reject bad trials\n    X_tr = X_tr[:,:-3,:] # pick EEG channels\n    X_tr = X_tr*1e6 #uV\n    X_tr = np.squeeze(tf_repr.transform(X_tr))\n    # testing\n    db.load_subject(sbj, mode = 'evaluation')\n    X_ts, y_ts = db.get_data(classes=classes) #Load all classes, all channels {EEG, EOG}, reject bad trials\n    X_ts = X_ts[:,:-3,:] # pick EEG channels\n    X_ts = X_ts*1e6 #uV\n    X_ts = np.squeeze(tf_repr.transform(X_ts))\n    # merge both training and evaluation sets  \n    X = np.concatenate([X_tr, X_ts], axis = 0)\n    y = np.concatenate([y_tr, y_ts], axis = 0)    \n    # Resampling\n    if new_fs == fs:\n        print('No resampling, since new sampling rate same.')\n    else:\n        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2023-05-21T01:32:18.658232Z","iopub.execute_input":"2023-05-21T01:32:18.658973Z","iopub.status.idle":"2023-05-21T01:32:18.671773Z","shell.execute_reply.started":"2023-05-21T01:32:18.658937Z","shell.execute_reply":"2023-05-21T01:32:18.670594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the model (Gaussian functional conectivity network)","metadata":{}},{"cell_type":"code","source":"class GFC(Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def build(self, batch_input_shape):\n        self.gammad = self.add_weight(name = 'gammad',\n                                shape = (),\n                                initializer = 'zeros',\n                                trainable = True)\n        super().build(batch_input_shape)\n\n    def call(self, X): \n        X = tf.transpose(X, perm  = (0, 3, 1, 2)) #(N, F, C, T)\n        R = tf.reduce_sum(tf.math.multiply(X, X), axis = -1, keepdims = True) #(N, F, C, 1)\n        D  = R - 2*tf.matmul(X, X, transpose_b = True) + tf.transpose(R, perm = (0, 1, 3, 2)) #(N, F, C, C)\n\n        ones = tf.ones_like(D[0,0,...]) #(C, C)\n        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n        triu = tf.expand_dims(tf.boolean_mask(D, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n        sigma = tfp.stats.percentile(tf.math.sqrt(triu), 50, axis = 2, keepdims = True) #(N, F, 1, 1)\n\n        A = tf.math.exp(-1/(2*tf.pow(10., self.gammad)*tf.math.square(sigma))*D) #(N, F, C, C)\n        A.set_shape(D.shape)\n        return A\n\n    def compute_output_shape(self, batch_input_shape):\n        N, C, T, F = batch_input_shape.as_list()\n        return tf.TensorShape([N, F, C, C])\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {**base_config}\n\n\nclass get_triu(Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def build(self, batch_input_shape):\n        super().build(batch_input_shape)\n\n    def call(self, X): \n        N, F, C, C = X.shape\n        ones = tf.ones_like(X[0,0,...]) #(C, C)\n        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n        triu = tf.expand_dims(tf.boolean_mask(X, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n\n        triu.set_shape([N,F,int(C*(C-1)/2),1])\n        return triu\n\n    def compute_output_shape(self, batch_input_shape):\n        N, F, C, C = batch_input_shape.as_list()\n        return tf.TensorShape([N, F, int(C*(C-1)/2),1])\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {**base_config}\n    \n    \ndef GFC_triu_net_avg(nb_classes: int,\n          Chans: int,\n          Samples: int,\n          l1: int = 0, \n          l2: int = 0, \n          dropoutRate: float = 0.5,\n          filters: int = 1, \n          maxnorm: float = 2.0,\n          maxnorm_last_layer: float = 0.5,\n          kernel_time_1: int = 20,\n          strid_filter_time_1: int = 1,\n          bias_spatial: bool = False) -> Model:\n\n\n    input_main   = Input((Chans, Samples, 1),name='Input')                    \n    \n    block        = Conv2D(filters,(1,kernel_time_1),strides=(1,strid_filter_time_1),\n                            use_bias=bias_spatial,\n                            kernel_constraint = max_norm(maxnorm, axis=(0,1,2))\n                            )(input_main)\n    \n    block        = BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n\n    block        = Activation('elu')(block)      \n    \n    block        = GFC()(block)\n\n    block        = get_triu()(block)\n\n    block        = AveragePooling2D(pool_size=(block.shape[1],1),strides=(1,1))(block)\n    \n    block        = BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n\n    block        = Activation('elu')(block) \n    \n    block        = Flatten()(block)    \n\n    block        = Dropout(dropoutRate)(block) \n\n    block        = Dense(nb_classes, kernel_regularizer=L1L2(l1=l1,l2=l2),name='logits',\n                              kernel_constraint = max_norm(maxnorm_last_layer)\n                              )(block)\n\n    softmax      = Activation('softmax',name='output')(block)\n    \n    return Model(inputs=input_main, outputs=softmax)","metadata":{"papermill":{"duration":4.643402,"end_time":"2022-10-22T22:02:34.006275","exception":false,"start_time":"2022-10-22T22:02:29.362873","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-21T01:32:19.722879Z","iopub.execute_input":"2023-05-21T01:32:19.723292Z","iopub.status.idle":"2023-05-21T01:32:19.753889Z","shell.execute_reply.started":"2023-05-21T01:32:19.723232Z","shell.execute_reply":"2023-05-21T01:32:19.752591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiment","metadata":{"execution":{"iopub.execute_input":"2022-10-22T22:02:34.07466Z","iopub.status.busy":"2022-10-22T22:02:34.074032Z","iopub.status.idle":"2022-10-22T22:02:34.086988Z","shell.execute_reply":"2022-10-22T22:02:34.086008Z"},"papermill":{"duration":0.049558,"end_time":"2022-10-22T22:02:34.089324","exception":false,"start_time":"2022-10-22T22:02:34.039766","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Experiment configuration ","metadata":{}},{"cell_type":"code","source":"seed=23\nfolds=5\nepochs_train = 500 #500\ndata_set='GIGA_MI_ME'## BCICIV2a # GIGA_MI_ME\nnum_class = 2 \n\nsave_folder = 'GFC_triu_avg_128Hz'\nExperiment=f'{data_set}_{num_class}_class_{folds}_fold'\n\nmodel_name= f'{save_folder}{epochs_train}_epoch'\n","metadata":{"papermill":{"duration":0.048584,"end_time":"2022-10-22T22:02:34.171415","exception":false,"start_time":"2022-10-22T22:02:34.122831","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-21T01:32:23.489273Z","iopub.execute_input":"2023-05-21T01:32:23.490063Z","iopub.status.idle":"2023-05-21T01:32:23.496573Z","shell.execute_reply.started":"2023-05-21T01:32:23.490016Z","shell.execute_reply":"2023-05-21T01:32:23.495526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH=f'./{save_folder}/'\n!mkdir '{PATH}'","metadata":{"papermill":{"duration":0.045356,"end_time":"2022-10-22T22:02:34.249203","exception":false,"start_time":"2022-10-22T22:02:34.203847","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-21T01:32:24.705983Z","iopub.execute_input":"2023-05-21T01:32:24.70639Z","iopub.status.idle":"2023-05-21T01:32:25.702511Z","shell.execute_reply.started":"2023-05-21T01:32:24.706354Z","shell.execute_reply":"2023-05-21T01:32:25.701037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run experiment","metadata":{"execution":{"iopub.execute_input":"2022-10-22T22:02:35.565905Z","iopub.status.busy":"2022-10-22T22:02:35.565531Z","iopub.status.idle":"2022-10-22T22:02:35.582215Z","shell.execute_reply":"2022-10-22T22:02:35.581284Z"},"papermill":{"duration":0.051828,"end_time":"2022-10-22T22:02:35.58406","exception":false,"start_time":"2022-10-22T22:02:35.532232","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tf.random.set_seed(seed)\n\nif data_set=='GIGA_MI_ME':\n    subjects = np.arange(52)+1\n    subjects = np.delete(subjects,[28,33])\n    db = GIGA_MI_ME('../input/giga-mi-me/GIGA_MI_ME/') # update path\n    load_args = dict(db = db,\n                fs = db.metadata['sampling_rate'],\n                f_bank = np.asarray([[4., 40.]]),\n                vwt = None,#np.asarray([[2.5, 5]]),\n                new_fs = 128.0)    \nelif data_set=='BCICIV2a':\n    subjects = np.arange(9)+1\n    db = Dataset_2a('../input/bciciv2a/BCI_CIV_2a/') # update path\n    load_args = dict(db = db,\n                fs = db.metadata['sampling_rate'],\n                f_bank = np.asarray([[4., 40.]]),\n                vwt = np.asarray([[2.5, 6]]),\n                new_fs = 128.0,\n                num_class=num_class)\nelse:\n    print('Select a valid dataset')            \n\nt=time()\nsubjects_=[41,25,51]\nfor sbj in subjects_:\n    load_args['sbj'] = sbj\n    if data_set=='GIGA_MI_ME':\n        X_train, y_train = load_GIGA(**load_args)\n    elif data_set=='BCICIV2a':\n        X_train, y_train = load_BCICIV2a(**load_args)\n    X_train = X_train[..., np.newaxis]\n    Y_train = tf.keras.utils.to_categorical(y_train,num_classes=num_class)\n    # build model\n    clf = KerasClassifier(\n        GFC_triu_net_avg,\n        random_state=seed,\n        \n        #model hyperparameters\n        nb_classes=num_class, \n        Chans = X_train.shape[1], \n        Samples = X_train.shape[2],\n        dropoutRate=0.5,\n        l1 = 0, l2 = 0,\n        filters=2, maxnorm=2.0,maxnorm_last_layer=0.5,\n        kernel_time_1=25,strid_filter_time_1= 1,\n        bias_spatial = False,\n\n        #model config\n        verbose=0,\n        batch_size=500, #full batch        \n        loss=tf.keras.losses.CategoricalCrossentropy(),\n        optimizer=\"adam\",\n        optimizer_learning__rate=0.1,\n        metrics = ['accuracy'],\n        epochs = epochs_train\n    )\n    # search params\n    param_grid =  {\n                'filters':[2,4], #2,4\n                'kernel_time_1':[25,50], #25,50\n                }\n    \n    #Gridsearch\n    scoring = {\"AUC\": 'roc_auc', \"Accuracy\": make_scorer(accuracy_score),'Kappa':make_scorer(kappa)}\n    \n    cv = GridSearchCV(clf,param_grid,cv=StratifiedShuffleSplit(n_splits = folds, test_size = 0.2, random_state = seed),\n                         verbose=0,n_jobs=1,\n                         scoring=scoring,\n                         refit=\"Accuracy\",\n                            )\n    # frind best params with gridsearch\n    cv.fit(X_train,Y_train)\n    # best score\n    print('Subject',sbj,'Accuracy',cv.best_score_,'elapsed time',time()-t)\n    print('---------')\n    \n    cv.cv_results_['best_index_']=cv.best_index_\n    \n    #########\n    cv.best_estimator_.model_.save_weights(f'{PATH}Model_{Experiment}_{model_name}_sujeto_{sbj}_'+data_set+'_4_40_weights.h5')\n    with open(PATH+'Results_'+Experiment+'_'+model_name+'_sujeto_'+str(sbj)+'_'+data_set+'_4_40.p','wb') as f:\n        pickle.dump(cv.cv_results_,f)     ","metadata":{"papermill":{"duration":16769.446163,"end_time":"2022-10-23T02:42:05.14864","exception":false,"start_time":"2022-10-22T22:02:35.702477","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-11-13T03:10:07.530716Z","iopub.execute_input":"2022-11-13T03:10:07.531136Z","iopub.status.idle":"2022-11-13T03:11:02.581663Z","shell.execute_reply.started":"2022-11-13T03:10:07.531093Z","shell.execute_reply":"2022-11-13T03:11:02.580564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r ./MI_EEG_ClassMeth\n!rm -r ./__MACOSX\n!rm ./MI_EEG_ClassMeth.zip","metadata":{"execution":{"iopub.status.busy":"2022-11-13T03:11:31.827199Z","iopub.execute_input":"2022-11-13T03:11:31.827609Z","iopub.status.idle":"2022-11-13T03:11:34.869765Z","shell.execute_reply.started":"2022-11-13T03:11:31.827576Z","shell.execute_reply":"2022-11-13T03:11:34.868312Z"},"trusted":true},"execution_count":null,"outputs":[]}]}